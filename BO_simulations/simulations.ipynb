{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulations of PPE using Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will perform simulations for known probabilistic distributions of a target $Y$, aiming to evaluate the effectiveness of Bayesian Optimization (BO) for inferring an optimal set of hyperparameters. To achieve that, we will assume a probabilistic distribution $Y | \\pmb{\\theta} \\sim \\pi_{Y | \\pmb{\\theta}}$, where $\\pmb{\\theta}\\sim\\pi_{\\pmb{\\theta}}$, with $\\pi_{\\pmb{\\theta}}$ belonging to a family of distributions that is indexed by a hyperparameter vector $\\pmb{\\lambda}$. For a fixed value $\\pmb{\\lambda_{\\text{true}}}$, we will obtain simulated expert probabilities for a given partition, which we will subsequently use to perform PPE using BO. The experiment will involve partitions with different number of bins, and also different number of covariates $J$, whenever the target is dependent on a set of covariates, to test how efficient the method is with more detailed partitions and also more covariate sets for which there is expert input.\n",
    "\n",
    "We will run simulations for three different families of probabilistic models. The first is the gaussian family, where we assume that $$Y\\sim \\mathcal{N}(\\mu, \\sigma^2),$$ with different possible priors then used to define $\\mu$ and $\\sigma$.\n",
    "\n",
    "The second probabilistic model family again assumes that $Y$ is drawn from a gaussian distribution, but now the mean is estimated as a linear combination of a set of covariates $x_1,...,x_n$:\n",
    "$$Y\\sim\\mathcal{N}(b_0 + \\prod_{i=1}^{n}b_i\\cdot x_i, \\sigma^2),$$\n",
    "\n",
    "where $b_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i)$.\n",
    "\n",
    "The third family is that of logistic regression, where $Y$ is now binary and a function of covariates x = \\{$x_1,...,x_n$\\}. In probabilistic notation, we have:\n",
    "\n",
    "$$Y\\sim\\mathcal{B}(p(\\pmb{x}, \\pmb{\\theta})),$$\n",
    "\n",
    "where $p(\\pmb{x}, \\pmb{\\theta}) = \\frac{e^{\\pmb{x}^{\\Tau} \\pmb{\\theta}}}{1 + e^{\\pmb{x}^{\\Tau} \\pmb{\\theta}}}$, with $\\theta_i \\sim \\mathcal{N}(\\mu_i, \\sigma_i^2)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import make_partition, ppe_simulation, make_plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Family 1: Gaussian distribution with no covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model family, we will test two models, namely Model 1 and Model 2. For each, we will implement PPE with BO, considering multiple partitionings, each with a different number of bins. We will test partitionings with 2, 5, 10 and 20 bins. The way we construct the partitionings is by taking an area where $Y$ is \"more likely to be into\", and partition it according to the number of bins. Then, we also consider two additional partitions for the lower and upper tails of the distribution so that the total number of bins is the one desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaussian_models import gaussian_model_1, gaussian_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.e+04,  5.e+00],\n",
       "        [ 5.e+00,  1.e+04]]),\n",
       " array([[-1.00000000e+04, -1.50000000e+01],\n",
       "        [-1.50000000e+01, -1.66666667e+00],\n",
       "        [-1.66666667e+00,  1.16666667e+01],\n",
       "        [ 1.16666667e+01,  2.50000000e+01],\n",
       "        [ 2.50000000e+01,  1.00000000e+04]]),\n",
       " array([[-1.0e+04, -1.5e+01],\n",
       "        [-1.5e+01, -1.0e+01],\n",
       "        [-1.0e+01, -5.0e+00],\n",
       "        [-5.0e+00,  0.0e+00],\n",
       "        [ 0.0e+00,  5.0e+00],\n",
       "        [ 5.0e+00,  1.0e+01],\n",
       "        [ 1.0e+01,  1.5e+01],\n",
       "        [ 1.5e+01,  2.0e+01],\n",
       "        [ 2.0e+01,  2.5e+01],\n",
       "        [ 2.5e+01,  1.0e+04]]),\n",
       " array([[-1.00000000e+04, -1.50000000e+01],\n",
       "        [-1.50000000e+01, -1.27777778e+01],\n",
       "        [-1.27777778e+01, -1.05555556e+01],\n",
       "        [-1.05555556e+01, -8.33333333e+00],\n",
       "        [-8.33333333e+00, -6.11111111e+00],\n",
       "        [-6.11111111e+00, -3.88888889e+00],\n",
       "        [-3.88888889e+00, -1.66666667e+00],\n",
       "        [-1.66666667e+00,  5.55555556e-01],\n",
       "        [ 5.55555556e-01,  2.77777778e+00],\n",
       "        [ 2.77777778e+00,  5.00000000e+00],\n",
       "        [ 5.00000000e+00,  7.22222222e+00],\n",
       "        [ 7.22222222e+00,  9.44444444e+00],\n",
       "        [ 9.44444444e+00,  1.16666667e+01],\n",
       "        [ 1.16666667e+01,  1.38888889e+01],\n",
       "        [ 1.38888889e+01,  1.61111111e+01],\n",
       "        [ 1.61111111e+01,  1.83333333e+01],\n",
       "        [ 1.83333333e+01,  2.05555556e+01],\n",
       "        [ 2.05555556e+01,  2.27777778e+01],\n",
       "        [ 2.27777778e+01,  2.50000000e+01],\n",
       "        [ 2.50000000e+01,  1.00000000e+04]])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bins = np.array([2, 5, 10, 20])\n",
    "\n",
    "gaussian_partitions = [make_partition(n, 5 - 20, 5 + 20) for n in num_bins]\n",
    "\n",
    "gaussian_partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "For the first model, we assume that $Y\\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu \\sim \\mathcal{N}(\\mu_1, \\sigma_1)$ and $\\sigma \\sim \\text{Gamma}(a, b)$. Our hyperparameter vector is then $\\pmb{\\lambda} = [\\mu_1, \\sigma_1, a, b]$. For the simulation, we assume that $\\mu_1 = 5, \\sigma_1 = 2, a = 2$ and $b = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter mu_1. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 07-01 17:15:38] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter sigma_1. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 07-01 17:15:38] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter a. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 07-01 17:15:38] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter b. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 07-01 17:15:38] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter alpha. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 07-01 17:15:38] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='mu_1', parameter_type=FLOAT, range=[-10.0, 10.0]), RangeParameter(name='sigma_1', parameter_type=FLOAT, range=[0.001, 10.0]), RangeParameter(name='a', parameter_type=FLOAT, range=[0.001, 10.0]), RangeParameter(name='b', parameter_type=FLOAT, range=[0.001, 10.0]), RangeParameter(name='alpha', parameter_type=FLOAT, range=[0.001, 70.0])], parameter_constraints=[]).\n",
      "[INFO 07-01 17:15:38] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 07-01 17:15:38] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=5 num_trials=None use_batch_trials=False\n",
      "[INFO 07-01 17:15:38] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=10\n",
      "[INFO 07-01 17:15:38] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=10\n",
      "[INFO 07-01 17:15:38] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 07-01 17:15:38] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 10 trials, BoTorch for subsequent trials]). Iterations after 10 will take longer to generate due to model-fitting.\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Started full optimization with 75 steps.\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 1...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 2...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 3...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 4...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 5...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 6...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 7...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 8...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 9...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 10...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:38] ax.service.managed_loop: Running optimization trial 11...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:39] ax.service.managed_loop: Running optimization trial 12...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:39] ax.service.managed_loop: Running optimization trial 13...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:40] ax.service.managed_loop: Running optimization trial 14...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:40] ax.service.managed_loop: Running optimization trial 15...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:41] ax.service.managed_loop: Running optimization trial 16...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:41] ax.service.managed_loop: Running optimization trial 17...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:42] ax.service.managed_loop: Running optimization trial 18...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:42] ax.service.managed_loop: Running optimization trial 19...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:43] ax.service.managed_loop: Running optimization trial 20...\n",
      "Sampling: [Y_obs, mu, sigma]\n",
      "[INFO 07-01 17:15:44] ax.service.managed_loop: Running optimization trial 21...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m alphas_gaussian_1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(num_bins))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_bins\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 25\u001b[0m     expert_probs, best_params, best_probs, alpha \u001b[38;5;241m=\u001b[39m \u001b[43mppe_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgaussian_model_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mlambd_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlambd_names_gaussian_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mlambd_true_vals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlambd_true_vals_gaussian_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mnum_bins\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_bins\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mlower_inner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlower_inner_gaussian_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mupper_inner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mupper_inner_gaussian_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mparam_bounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_bounds_gaussian_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mtarget_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     simulated_expert_probs_gaussian_1 \u001b[38;5;241m=\u001b[39m expert_probs\n\u001b[1;32m     38\u001b[0m     best_params_gaussian_1 \u001b[38;5;241m=\u001b[39m best_params\n",
      "File \u001b[0;32m~/Documents/GitHub/Prior-Predictive-Elicitation/BO_simulations/functions.py:107\u001b[0m, in \u001b[0;36mppe_simulation\u001b[0;34m(model, J, target_type, lambd_names, lambd_true_vals, alpha, num_bins, lower_inner, upper_inner, param_bounds, target_samples, n_trials)\u001b[0m\n\u001b[1;32m    104\u001b[0m param_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrange\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(lambd_names)\n\u001b[1;32m    105\u001b[0m param_expected_vals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(lambd_names) \u001b[38;5;66;03m## we only focus on the dirichlet log likelihood\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mBO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambd_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparam_types\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparam_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparam_expected_vals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_expected_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparam_weights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mexpert_probs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimulated_expert_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m best_alpha \u001b[38;5;241m=\u001b[39m BO\u001b[38;5;241m.\u001b[39meval_function(best_params, [partition]\u001b[38;5;241m*\u001b[39mJ, simulated_expert_probs) \u001b[38;5;66;03m##alpha\u001b[39;00m\n\u001b[1;32m    118\u001b[0m best_probs \u001b[38;5;241m=\u001b[39m BO\u001b[38;5;241m.\u001b[39mget_model_probs(lam \u001b[38;5;241m=\u001b[39m best_params, partitions \u001b[38;5;241m=\u001b[39m [partition]\u001b[38;5;241m*\u001b[39mJ, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20_000\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Prior-Predictive-Elicitation/ppe/bayesian_optimization.py:182\u001b[0m, in \u001b[0;36mBayesian_Optimization.optimize_hyperparams\u001b[0;34m(self, param_names, param_types, param_bounds, param_expected_vals, param_weights, partitions, expert_probs, n_trials)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: bound}\n\u001b[1;32m    180\u001b[0m parameters \u001b[38;5;241m=\u001b[39m [create_param_dict(name, \u001b[38;5;28mtype\u001b[39m, bound) \u001b[38;5;28;01mfor\u001b[39;00m name, \u001b[38;5;28mtype\u001b[39m, bound \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(param_names, param_types, param_bounds)]\n\u001b[0;32m--> 182\u001b[0m best_lam, values, experiment, model \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_neg_llik\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDirichlet_negative_log_likelihood\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_lam\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/service/managed_loop.py:306\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(parameters, evaluation_function, experiment_name, objective_name, minimize, parameter_constraints, outcome_constraints, total_trials, arms_per_trial, random_seed, generation_strategy)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct and run a full optimization loop.\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m loop \u001b[38;5;241m=\u001b[39m OptimizationLoop\u001b[38;5;241m.\u001b[39mwith_evaluation_function(\n\u001b[1;32m    294\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    295\u001b[0m     objective_name\u001b[38;5;241m=\u001b[39mobjective_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     generation_strategy\u001b[38;5;241m=\u001b[39mgeneration_strategy,\n\u001b[1;32m    305\u001b[0m )\n\u001b[0;32m--> 306\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m parameterization, values \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mget_best_point()\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parameterization, values, loop\u001b[38;5;241m.\u001b[39mexperiment, loop\u001b[38;5;241m.\u001b[39mget_current_model()\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/service/managed_loop.py:237\u001b[0m, in \u001b[0;36mOptimizationLoop.full_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SearchSpaceExhausted \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    239\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped optimization as the search space is exhaused. Message \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom generation strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/utils/common/executils.py:163\u001b[0m, in \u001b[0;36mretry_on_exception.<locals>.func_wrapper.<locals>.actual_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m             wait_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    160\u001b[0m                 MAX_WAIT_SECONDS, initial_wait_seconds \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    161\u001b[0m             )\n\u001b[1;32m    162\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(wait_interval)\n\u001b[0;32m--> 163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# If we are here, it means the retries were finished but\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# The error was suppressed. Hence return the default value provided.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default_return_on_suppression\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/service/managed_loop.py:210\u001b[0m, in \u001b[0;36mOptimizationLoop.run_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization is complete, cannot run another trial.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning optimization trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_trial\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_new_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m trial\u001b[38;5;241m.\u001b[39mmark_running(no_runner_required\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    213\u001b[0m _, data \u001b[38;5;241m=\u001b[39m data_and_evaluations_from_raw_data(\n\u001b[1;32m    214\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    215\u001b[0m         arm\u001b[38;5;241m.\u001b[39mname: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_evaluation_function(arm\u001b[38;5;241m.\u001b[39mparameters, weight)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m     )\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mmetric_names,\n\u001b[1;32m    224\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/service/managed_loop.py:168\u001b[0m, in \u001b[0;36mOptimizationLoop._get_new_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_new_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseTrial:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marms_per_trial \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mnew_trial(\n\u001b[0;32m--> 168\u001b[0m             generator_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_pending_observation_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marms_per_trial \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mnew_batch_trial(\n\u001b[1;32m    177\u001b[0m             generator_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_strategy\u001b[38;5;241m.\u001b[39mgen(\n\u001b[1;32m    178\u001b[0m                 experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marms_per_trial\n\u001b[1;32m    179\u001b[0m             )\n\u001b[1;32m    180\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/generation_strategy.py:370\u001b[0m, in \u001b[0;36mGenerationStrategy.gen\u001b[0;34m(self, experiment, data, n, pending_observations, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m(\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    337\u001b[0m     experiment: Experiment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    342\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GeneratorRun:\n\u001b[1;32m    343\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Produce the next points in the experiment. Additional kwargs passed to\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    this method are propagated directly to the underlying model's `gen`, along\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    with the `model_gen_kwargs` set on the current generation node.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m            resuggesting points that are currently being evaluated.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_multiple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_generator_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/generation_strategy.py:683\u001b[0m, in \u001b[0;36mGenerationStrategy._gen_multiple\u001b[0;34m(self, experiment, num_generator_runs, data, n, pending_observations, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generator_runs):\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 683\u001b[0m         generator_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m            \u001b[49m\u001b[43marms_by_signature_for_deduplication\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marms_by_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DataRequiredError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;66;03m# Model needs more data, so we log the error and return\u001b[39;00m\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;66;03m# as many generator runs as we were able to produce, unless\u001b[39;00m\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;66;03m# no trials were produced at all (in which case its safe to raise).\u001b[39;00m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(generator_runs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/generation_node.py:712\u001b[0m, in \u001b[0;36mGenerationStep.gen\u001b[0;34m(self, n, pending_observations, max_gen_draws_for_deduplication, arms_by_signature_for_deduplication, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m(\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    706\u001b[0m     n: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_gen_kwargs: Any,\n\u001b[1;32m    711\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GeneratorRun:\n\u001b[0;32m--> 712\u001b[0m     gr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_gen_draws_for_deduplication\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gen_draws_for_deduplication\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43marms_by_signature_for_deduplication\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marms_by_signature_for_deduplication\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     gr\u001b[38;5;241m.\u001b[39m_generation_step_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gr\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/generation_node.py:272\u001b[0m, in \u001b[0;36mGenerationNode.gen\u001b[0;34m(self, n, pending_observations, max_gen_draws_for_deduplication, arms_by_signature_for_deduplication, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Keep generating until each of `generator_run.arms` is not a duplicate\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# of a previous arm, if `should_deduplicate is True`\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m should_generate_run:\n\u001b[0;32m--> 272\u001b[0m     generator_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     should_generate_run \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_deduplicate\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m arms_by_signature_for_deduplication\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         )\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     n_gen_draws \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/generation_node.py:334\u001b[0m, in \u001b[0;36mGenerationNode._gen\u001b[0;34m(self, n, pending_observations, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m model_spec\u001b[38;5;241m.\u001b[39mmodel_gen_kwargs:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;66;03m# If `n` is not specified, ensure that the `None` value does not\u001b[39;00m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;66;03m# override the one set in `model_spec.model_gen_kwargs`.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     n \u001b[38;5;241m=\u001b[39m model_spec\u001b[38;5;241m.\u001b[39mmodel_gen_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# For `pending_observations`, prefer the input to this function, as\u001b[39;49;00m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `pending_observations` are dynamic throughout the experiment and thus\u001b[39;49;00m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# unlikely to be specified in `model_spec.model_gen_kwargs`.\u001b[39;49;00m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/model_spec.py:221\u001b[0m, in \u001b[0;36mModelSpec.gen\u001b[0;34m(self, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_model\n\u001b[1;32m    214\u001b[0m model_gen_kwargs \u001b[38;5;241m=\u001b[39m consolidate_kwargs(\n\u001b[1;32m    215\u001b[0m     kwargs_iterable\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_gen_kwargs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     keywords\u001b[38;5;241m=\u001b[39mget_function_argument_names(fitted_model\u001b[38;5;241m.\u001b[39mgen),\n\u001b[1;32m    220\u001b[0m )\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfitted_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/base.py:786\u001b[0m, in \u001b[0;36mModelBridge.gen\u001b[0;34m(self, n, search_space, optimization_config, pending_observations, fixed_features, model_gen_options)\u001b[0m\n\u001b[1;32m    779\u001b[0m base_gen_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_transformed_gen_args(\n\u001b[1;32m    780\u001b[0m     search_space\u001b[38;5;241m=\u001b[39msearch_space,\n\u001b[1;32m    781\u001b[0m     optimization_config\u001b[38;5;241m=\u001b[39moptimization_config,\n\u001b[1;32m    782\u001b[0m     pending_observations\u001b[38;5;241m=\u001b[39mpending_observations,\n\u001b[1;32m    783\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mfixed_features,\n\u001b[1;32m    784\u001b[0m )\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# Apply terminal transform and gen\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m gen_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_gen_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_gen_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m observation_features \u001b[38;5;241m=\u001b[39m gen_results\u001b[38;5;241m.\u001b[39mobservation_features\n\u001b[1;32m    796\u001b[0m best_obsf \u001b[38;5;241m=\u001b[39m gen_results\u001b[38;5;241m.\u001b[39mbest_observation_features\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/modelbridge/torch.py:686\u001b[0m, in \u001b[0;36mTorchModelBridge._gen\u001b[0;34m(self, n, search_space, pending_observations, fixed_features, model_gen_options, optimization_config)\u001b[0m\n\u001b[1;32m    677\u001b[0m search_space_digest, torch_opt_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_transformed_model_gen_args(\n\u001b[1;32m    678\u001b[0m     search_space\u001b[38;5;241m=\u001b[39msearch_space,\n\u001b[1;32m    679\u001b[0m     pending_observations\u001b[38;5;241m=\u001b[39mpending_observations,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    682\u001b[0m     optimization_config\u001b[38;5;241m=\u001b[39moptimization_config,\n\u001b[1;32m    683\u001b[0m )\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# Generate the candidates\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m gen_results \u001b[38;5;241m=\u001b[39m \u001b[43mnot_none\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_opt_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_opt_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m gen_metadata \u001b[38;5;241m=\u001b[39m gen_results\u001b[38;5;241m.\u001b[39mgen_metadata\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(optimization_config, MultiObjectiveOptimizationConfig)\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m gen_metadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective_thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# if using a hypervolume based acquisition function, then\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# the inferred objective thresholds are in gen_metadata.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/models/torch/botorch_modular/model.py:428\u001b[0m, in \u001b[0;36mBoTorchModel.gen\u001b[0;34m(self, n, search_space_digest, torch_opt_config)\u001b[0m\n\u001b[1;32m    422\u001b[0m acqf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instantiate_acquisition(\n\u001b[1;32m    423\u001b[0m     search_space_digest\u001b[38;5;241m=\u001b[39msearch_space_digest,\n\u001b[1;32m    424\u001b[0m     torch_opt_config\u001b[38;5;241m=\u001b[39mtorch_opt_config,\n\u001b[1;32m    425\u001b[0m     acq_options\u001b[38;5;241m=\u001b[39macq_options,\n\u001b[1;32m    426\u001b[0m )\n\u001b[1;32m    427\u001b[0m botorch_rounding_func \u001b[38;5;241m=\u001b[39m get_rounding_func(torch_opt_config\u001b[38;5;241m.\u001b[39mrounding_func)\n\u001b[0;32m--> 428\u001b[0m candidates, expected_acquisition_value, weights \u001b[38;5;241m=\u001b[39m \u001b[43macqf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_to_inequality_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_opt_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_constraints\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_opt_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrounding_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbotorch_rounding_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecked_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m gen_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gen_metadata_from_acqf(\n\u001b[1;32m    439\u001b[0m     acqf\u001b[38;5;241m=\u001b[39macqf,\n\u001b[1;32m    440\u001b[0m     torch_opt_config\u001b[38;5;241m=\u001b[39mtorch_opt_config,\n\u001b[1;32m    441\u001b[0m     expected_acquisition_value\u001b[38;5;241m=\u001b[39mexpected_acquisition_value,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TorchGenResults(\n\u001b[1;32m    444\u001b[0m     points\u001b[38;5;241m=\u001b[39mcandidates\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(),\n\u001b[1;32m    445\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    446\u001b[0m     gen_metadata\u001b[38;5;241m=\u001b[39mgen_metadata,\n\u001b[1;32m    447\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/ax/models/torch/botorch_modular/acquisition.py:450\u001b[0m, in \u001b[0;36mAcquisition.optimize\u001b[0;34m(self, n, search_space_digest, inequality_constraints, fixed_features, rounding_func, optimizer_options)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# 1. Handle the fully continuous search space.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    447\u001b[0m     optimizer_options_with_defaults\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_use_optimize_acqf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m discrete_features\n\u001b[1;32m    449\u001b[0m ):\n\u001b[0;32m--> 450\u001b[0m     candidates, acqf_values \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_processing_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_processing_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_options_with_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m candidates, acqf_values, arm_weights\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# 2. Handle search spaces with discrete features.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/optim/optimize.py:567\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[1;32m    545\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[1;32m    546\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[1;32m    547\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[1;32m    566\u001b[0m )\n\u001b[0;32m--> 567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/optim/optimize.py:588\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/optim/optimize.py:275\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mbatch_initial_conditions\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# pyre-ignore[28]: Unexpected keyword argument `acq_function` to anonymous call.\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ic_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_restarts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mic_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m batch_limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    290\u001b[0m     (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    294\u001b[0m     ),\n\u001b[1;32m    295\u001b[0m )\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_batch_candidates\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor, List[\u001b[38;5;167;01mWarning\u001b[39;00m]]:\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/optim/initializers.py:417\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints, generator, fixed_X_fantasies)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx \u001b[38;5;241m<\u001b[39m X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    416\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m batch_limit, X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 417\u001b[0m     Y_rnd_curr \u001b[38;5;241m=\u001b[39m \u001b[43macq_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_rnd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    420\u001b[0m     Y_rnd_list\u001b[38;5;241m.\u001b[39mappend(Y_rnd_curr)\n\u001b[1;32m    421\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_limit\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/utils/transforms.py:305\u001b[0m, in \u001b[0;36mconcatenate_pending_points.<locals>.decorated\u001b[0;34m(cls, X, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mX_pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([X, match_batch_shape(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mX_pending, X)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/utils/transforms.py:259\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    258\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    263\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    264\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/acquisition/monte_carlo.py:274\u001b[0m, in \u001b[0;36mSampleReducingMCAcquisitionFunction.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;129m@concatenate_pending_points\u001b[39m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;129m@t_batch_mode_transform\u001b[39m()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    257\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the acquisition value associated with the input `X`. Weighs the\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m    acquisition utility values by smoothed constraint indicators if `constraints`\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    was passed to the constructor of the class. Applies `self.sample_reduction` and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        batch shape of model and input `X`.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     non_reduced_acqval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_reduced_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_reduction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_q_reduction(non_reduced_acqval))\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/acquisition/monte_carlo.py:289\u001b[0m, in \u001b[0;36mSampleReducingMCAcquisitionFunction._non_reduced_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m samples, obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_samples_and_objectives(X)\n\u001b[1;32m    288\u001b[0m samples \u001b[38;5;241m=\u001b[39m repeat_to_match_aug_dim(target_tensor\u001b[38;5;241m=\u001b[39msamples, reference_tensor\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m--> 289\u001b[0m acqval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# `sample_sample x batch_shape x q`\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_constraints(acqval\u001b[38;5;241m=\u001b[39macqval, samples\u001b[38;5;241m=\u001b[39msamples)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/acquisition/logei.py:359\u001b[0m, in \u001b[0;36mqLogNoisyExpectedImprovement._sample_forward\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate qLogNoisyExpectedImprovement per sample on the candidate set `X`.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03m        improvement values.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_log_improvement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbest_f\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_best_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtau_relu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/acquisition/logei.py:536\u001b[0m, in \u001b[0;36m_log_improvement\u001b[0;34m(Y, best_f, tau, fat)\u001b[0m\n\u001b[1;32m    534\u001b[0m log_soft_clamp \u001b[38;5;241m=\u001b[39m log_fatplus \u001b[38;5;28;01mif\u001b[39;00m fat \u001b[38;5;28;01melse\u001b[39;00m log_softplus\n\u001b[1;32m    535\u001b[0m Z \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m-\u001b[39m best_f\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(Y)\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_soft_clamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/utils/safe_math.py:299\u001b[0m, in \u001b[0;36mlog_fatplus\u001b[0;34m(x, tau)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_fatplus\u001b[39m(x: Tensor, tau: Union[\u001b[38;5;28mfloat\u001b[39m, Tensor] \u001b[38;5;241m=\u001b[39m TAU) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Computes the logarithm of the fat-tailed softplus.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    NOTE: Separated out in case the complexity of the `log` implementation increases\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    in the future.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfatplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlog()\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/utils/safe_math.py:320\u001b[0m, in \u001b[0;36mfatplus\u001b[0;34m(x, tau)\u001b[0m\n\u001b[1;32m    317\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-1\u001b[39m  \u001b[38;5;66;03m# guarantees monotonicity and convexity (TODO: ref + Lemma 4)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m softplus(x) \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m cauchy(x)\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tau \u001b[38;5;241m*\u001b[39m \u001b[43m_fatplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppe3/lib/python3.11/site-packages/botorch/utils/safe_math.py:318\u001b[0m, in \u001b[0;36mfatplus.<locals>._fatplus\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fatplus\u001b[39m(x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    317\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-1\u001b[39m  \u001b[38;5;66;03m# guarantees monotonicity and convexity (TODO: ref + Lemma 4)\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msoftplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m cauchy(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mu_1 = 5 ; sigma_1 = 2 ; a = 2 ; b = 3\n",
    "\n",
    "lambd_names_gaussian_1 = [\"mu_1\", \"sigma_1\", \"a\", \"b\"] ## hyperparameter names\n",
    "lambd_true_vals_gaussian_1 = np.array([mu_1, sigma_1, a, b])\n",
    "param_bounds_gaussian_1 = [[-10., 10.], [0.001, 10.], [0.001, 10.], [0.001, 10.]] ## bounds for each hyperparameter\n",
    "alpha = None\n",
    "\n",
    "target_type = \"continuous\"\n",
    "target_samples = 1500\n",
    "J = 1\n",
    "\n",
    "lower_inner_gaussian_1 = 5 - 20\n",
    "upper_inner_gaussian_1 = 5 + 20\n",
    "\n",
    "\n",
    "\n",
    "simulated_expert_probs_gaussian_1 = np.zeros(len(num_bins))\n",
    "best_params_gaussian_1 = np.zeros(len(num_bins))\n",
    "best_probs_gaussian_1 = np.zeros(len(num_bins))\n",
    "alphas_gaussian_1 = np.zeros(len(num_bins))\n",
    "\n",
    "\n",
    "for i in range(num_bins.shape[0]):\n",
    "\n",
    "    expert_probs, best_params, best_probs, alpha = ppe_simulation(model = gaussian_model_1,\n",
    "                                                                  J = J,\n",
    "                                                                  target_type = target_type,\n",
    "                                                                  lambd_names = lambd_names_gaussian_1,\n",
    "                                                                  lambd_true_vals = lambd_true_vals_gaussian_1,\n",
    "                                                                  alpha = alpha,\n",
    "                                                                  num_bins = num_bins[i],\n",
    "                                                                  lower_inner = lower_inner_gaussian_1,\n",
    "                                                                  upper_inner = upper_inner_gaussian_1,\n",
    "                                                                  param_bounds = param_bounds_gaussian_1,\n",
    "                                                                  target_samples = target_samples)\n",
    "    \n",
    "    simulated_expert_probs_gaussian_1 = expert_probs\n",
    "    best_params_gaussian_1 = best_params\n",
    "    best_probs_gaussian_1 = best_probs\n",
    "    alphas_gaussian_1 = alpha\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "\n",
    "Similar to Model 1, we assume for Model 2 that $Y\\sim \\mathcal{N}(\\mu, \\sigma^2)$, where $\\mu \\sim \\mathcal{N}(\\mu_1, \\sigma_1)$ and $\\sigma \\sim \\text{Gamma}(a, b)$. The difference is that now we also assume hyperpriors for the parameters of $\\mu$'s prior, specifically $\\mu_1\\sim\\mathcal{N}(\\mu_m, \\sigma_m)$ and $\\sigma_1 \\sim \\mathcal{LN}(\\mu_s, \\sigma_s)$, where $\\mathcal{LN}$ is the log-gaussian distribution. This implies a hyperparameter vector $\\pmb{\\lambda} = [\\mu_m, \\sigma_m, \\mu_s, \\sigma_s, a, b]$. For the simulation, we assume that $\\mu_m = 5, \\sigma_m = 1, \\mu_s = 0.4, \\sigma_m = 4, a = 2$ and $b = 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppe3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
