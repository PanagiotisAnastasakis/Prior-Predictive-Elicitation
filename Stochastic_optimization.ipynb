{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad,jacobian,vmap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax.scipy.special as sps\n",
    "import jax.scipy.stats as scs\n",
    "from jax import random\n",
    "import pymc as pm\n",
    "from scipy.special import digamma\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class priors:\n",
    "    \n",
    "    def pivot(self, theta, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Pivot function of the distribution\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.pivot(theta, *args, **kwds)\n",
    "    \n",
    "    def inverse_pivot(self, x, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Inverse pivot function of the distribution\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.inverse_pivot(x, *args, **kwds)\n",
    "    \n",
    "    def sample_x(self, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to sample from X (independent from the hyperparameters lambda)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.sample_x(*args, **kwds)\n",
    "    \n",
    "    def grad_inverse_pivot(self, x, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Gradient of the inverse pivot with respect to the hyperparameters lambda\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.grad_inverse_pivot(x, *args, **kwds)\n",
    "    \n",
    "\n",
    "\n",
    "class model_probabilities:\n",
    "    \n",
    "    def __init__(self, is_discrete=False):\n",
    "        self.is_discrete = is_discrete\n",
    "    \n",
    "    def cdf(self, y, *args, **kwds):\n",
    "        \n",
    "        return self.cdf(y, *args, **kwds)\n",
    "    \n",
    "    def pdf(self, y, *args, **kwds):\n",
    "        \n",
    "        return self.pdf(y, *args, **kwds)\n",
    "    \n",
    "    def partition_prob(self, partition, *args, **kwds):\n",
    "        \n",
    "        if self.is_discrete:\n",
    "            return self.pdf(partition, *args, **kwds)\n",
    "        \n",
    "        a = partition[0]\n",
    "        b = partition[1]\n",
    "        \n",
    "        return self.cdf(b, *args, **kwds) - self.cdf(a, *args, **kwds)\n",
    "        \n",
    "    def grad_partition_prob(self, partition, *args, **kwds):\n",
    "        \n",
    "        return self.grad_partition_prob(partition, *args, **kwds)\n",
    "    \n",
    "\n",
    "class gaussian_prior(priors):\n",
    "    \n",
    "    def __init__(self, mu=None, sigma=None):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.is_discrete = False\n",
    "    \n",
    "    def _update(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def pivot(self, theta):\n",
    "        \n",
    "        return (theta - self.mu)/self.sigma\n",
    "    \n",
    "    def inverse_pivot(self, x):\n",
    "        \n",
    "        return x * self.sigma + self.mu\n",
    "    \n",
    "    def grad_inverse_pivot(self, x):\n",
    "        \n",
    "        dsigma = x\n",
    "        dmu = jnp.ones(len(dsigma)) if len(dsigma) > 1 else 1.\n",
    "        \n",
    "        return jnp.array([dmu, dsigma]) ## 1st row is dmu, 2nd row is dsigma\n",
    "    \n",
    "    def sample_x(self, size):\n",
    "        \n",
    "        return np.random.normal(size=size)\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class gaussian_model_probs(model_probabilities):\n",
    "    \n",
    "    def __init__(self, mu=None, sigma=None):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.is_discrete = False\n",
    "    \n",
    "    def _update(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def cdf(self, x):\n",
    "        \n",
    "        x = np.asarray(x)\n",
    "        return scs.norm.cdf(x, loc = self.mu, scale = self.sigma)\n",
    "    \n",
    "    def model_prob_gradient(self, partition):\n",
    "        \n",
    "        a = partition[0]\n",
    "        b = partition[1]\n",
    "        \n",
    "        #x = jnp.asarray(x)\n",
    "        \n",
    "        dmu = - (1/self.sigma) * scs.norm.pdf(b, loc=self.mu, scale=self.sigma) + (1/self.sigma) * scs.norm.pdf(a, loc=self.mu, scale=self.sigma)\n",
    "        dsigma = -((b - self.mu) / self.sigma**2) * scs.norm.pdf(b, loc=self.mu, scale=self.sigma) + ((a - self.mu) / self.sigma**2) * scs.norm.pdf(a, loc=self.mu, scale=self.sigma)\n",
    "        \n",
    "        return jnp.array([dmu, dsigma]) ## 1st row is dmu, 2nd row is dsigma\n",
    "        \n",
    "        #return grad(self.jax_helper_cdf, argnums=1)(b, self.mu, self.sigma) - grad(self.jax_helper_cdf, argnums=1)(a, self.mu, self.sigma) ### IMPROVE THIS WITH VMAP!!!\n",
    "    \n",
    "    #def jax_helper_cdf(self, x, params):\n",
    "        \n",
    "        #mu = params[0]\n",
    "        #sigma = params[1]\n",
    "        \n",
    "        #return scs.norm.cdf(x, loc = mu, scale = sigma)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12508571 -0.06117869 -0.1223839\n"
     ]
    }
   ],
   "source": [
    "mu_1 = 2.\n",
    "sigma = 1.\n",
    "sigma_1 = 2.\n",
    "\n",
    "partition = np.array([-2.,3.])\n",
    "\n",
    "\n",
    "gs_prior = gaussian_prior(mu = mu_1, sigma = sigma_1)\n",
    "\n",
    "x_samples = gs_prior.sample_x(1000000)\n",
    "\n",
    "theta = gs_prior.inverse_pivot(x_samples)\n",
    "\n",
    "gs_probs = gaussian_model_probs(mu = theta, sigma = sigma)\n",
    "\n",
    "prob_y_given_theta_dtheta_samples = gs_probs.model_prob_gradient(partition)[0,:]\n",
    "\n",
    "prob_y_given_theta_dsigma_samples = gs_probs.model_prob_gradient(partition)[1,:]\n",
    "\n",
    "pivot_gaussian_inverse_grad_samples = gs_prior.grad_inverse_pivot(x_samples)\n",
    "\n",
    "\n",
    "ppe_dmu1 = jnp.mean(prob_y_given_theta_dtheta_samples * pivot_gaussian_inverse_grad_samples[0,:])\n",
    "ppe_dsigma1 = jnp.mean(prob_y_given_theta_dtheta_samples * pivot_gaussian_inverse_grad_samples[1,:])\n",
    "ppe_dsigma = jnp.mean(prob_y_given_theta_dsigma_samples)\n",
    "\n",
    "print(ppe_dmu1, ppe_dsigma, ppe_dsigma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12541339 -0.06110352 -0.12220705]\n"
     ]
    }
   ],
   "source": [
    "def get_gaussian_probs(partition, lam):\n",
    "    \n",
    "    mu_1 = lam[0]\n",
    "    sigma = lam[1]\n",
    "    sigma_1 = lam[2]\n",
    "    \n",
    "    a = partition[0]\n",
    "    b = partition[1]\n",
    "    \n",
    "    p1 = scs.norm.cdf((b - mu_1)/jnp.sqrt(sigma**2 + sigma_1**2)) - scs.norm.cdf((a - mu_1)/jnp.sqrt(sigma**2 + sigma_1**2))    \n",
    "    \n",
    "    return p1\n",
    "\n",
    "lam = jnp.array([2., 1., 2.])\n",
    "partition = jnp.array([-2., 3.])\n",
    "\n",
    "print(grad(get_gaussian_probs, argnums=1)(partition, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppe3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
