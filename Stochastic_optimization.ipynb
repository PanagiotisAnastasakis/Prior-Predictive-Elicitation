{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad,jacobian,vmap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jax.scipy.special as sps\n",
    "import jax.scipy.stats as scs\n",
    "from jax import random\n",
    "import pymc as pm\n",
    "from scipy.special import digamma\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class priors:\n",
    "    \n",
    "    def pivot(self, theta, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Pivot function of the distribution\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.pivot(theta, *args, **kwds)\n",
    "    \n",
    "    def inverse_pivot(self, x, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Inverse pivot function of the distribution\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.inverse_pivot(x, *args, **kwds)\n",
    "    \n",
    "    def sample_x(self, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Function to sample from X (independent from the hyperparameters lambda)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.sample_x(*args, **kwds)\n",
    "    \n",
    "    def grad_inverse_pivot(self, x, *args, **kwds):\n",
    "        \n",
    "        \"\"\"\n",
    "        Gradient of the inverse pivot with respect to the hyperparameters lambda\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.grad_inverse_pivot(x, *args, **kwds)\n",
    "    \n",
    "\n",
    "\n",
    "class model_probabilities:\n",
    "    \n",
    "    def __init__(self, is_discrete=False):\n",
    "        self.is_discrete = is_discrete\n",
    "    \n",
    "    def cdf(self, y, *args, **kwds):\n",
    "        \n",
    "        return self.cdf(y, *args, **kwds)\n",
    "    \n",
    "    def pdf(self, y, *args, **kwds):\n",
    "        \n",
    "        return self.pdf(y, *args, **kwds)\n",
    "    \n",
    "    def partition_prob(self, partition, *args, **kwds):\n",
    "        \n",
    "        if self.is_discrete:\n",
    "            return self.pdf(partition, *args, **kwds)\n",
    "        \n",
    "        a = partition[0]\n",
    "        b = partition[1]\n",
    "        \n",
    "        return self.cdf(b, *args, **kwds) - self.cdf(a, *args, **kwds)\n",
    "        \n",
    "    def grad_partition_prob(self, partition, *args, **kwds):\n",
    "        \n",
    "        return self.grad_partition_prob(partition, *args, **kwds)\n",
    "    \n",
    "\n",
    "class gaussian_prior(priors):\n",
    "    \n",
    "    def __init__(self, mu=None, sigma=None):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.is_discrete = False\n",
    "    \n",
    "    def _update(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def pivot(self, theta):\n",
    "        \n",
    "        return (theta - self.mu)/self.sigma\n",
    "    \n",
    "    def inverse_pivot(self, x):\n",
    "        \n",
    "        return x * self.sigma + self.mu\n",
    "    \n",
    "    def grad_inverse_pivot(self, x):\n",
    "        \n",
    "        dsigma = x\n",
    "        dmu = jnp.ones(len(dsigma)) if len(dsigma) > 1 else 1.\n",
    "        \n",
    "        return jnp.array([dmu, dsigma]) ## 1st row is dmu, 2nd row is dsigma\n",
    "    \n",
    "    def sample_x(self, size):\n",
    "        \n",
    "        return np.random.normal(size=size)\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class gaussian_model_probs(model_probabilities):\n",
    "    \n",
    "    def __init__(self, mu=None, sigma=None):\n",
    "        super().__init__()\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.is_discrete = False\n",
    "    \n",
    "    def _update(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def cdf(self, x):\n",
    "        \n",
    "        x = np.asarray(x)\n",
    "        return scs.norm.cdf(x, loc = self.mu, scale = self.sigma)\n",
    "    \n",
    "    def model_prob_gradient(self, partition):\n",
    "        \n",
    "        a = partition[0]\n",
    "        b = partition[1]\n",
    "        \n",
    "        #x = jnp.asarray(x)\n",
    "        \n",
    "        dmu = - (1/self.sigma) * scs.norm.pdf(b, loc=self.mu, scale=self.sigma) + (1/self.sigma) * scs.norm.pdf(a, loc=self.mu, scale=self.sigma)\n",
    "        dsigma = -((b - self.mu) / self.sigma**2) * scs.norm.pdf(b, loc=self.mu, scale=self.sigma) + ((a - self.mu) / self.sigma**2) * scs.norm.pdf(a, loc=self.mu, scale=self.sigma)\n",
    "        \n",
    "        return jnp.array([dmu, dsigma]) ## 1st row is dmu, 2nd row is dsigma\n",
    "        \n",
    "        #return grad(self.jax_helper_cdf, argnums=1)(b, self.mu, self.sigma) - grad(self.jax_helper_cdf, argnums=1)(a, self.mu, self.sigma) ### IMPROVE THIS WITH VMAP!!!\n",
    "    \n",
    "    #def jax_helper_cdf(self, x, params):\n",
    "        \n",
    "        #mu = params[0]\n",
    "        #sigma = params[1]\n",
    "        \n",
    "        #return scs.norm.cdf(x, loc = mu, scale = sigma)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class bernoulli_model_probs(model_probabilities):\n",
    "    \n",
    "    def __init__(self, p=None):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.is_discrete = True\n",
    "    \n",
    "    def _update(self, p):\n",
    "        self.p = p\n",
    "        \n",
    "    def cdf(self, x):\n",
    "        \n",
    "        x = np.asarray(x)\n",
    "        return scs.bernoulli.cdf(x, p=self.p)\n",
    "    \n",
    "    def model_prob_gradient(self, partition):\n",
    "        \n",
    "        #x = jnp.asarray(x)\n",
    "        \n",
    "        dp = jnp.array([2*partition - 1]*len(self.p))\n",
    "        \n",
    "        return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prob_input(theta, covariate):\n",
    "    \n",
    "    return scs.norm.cdf(theta @ covariate, loc=0, scale=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D\n",
    "\n",
    "mu_1 = 1.\n",
    "sigma_1 = 0.7\n",
    "\n",
    "mu_2 = 0.5\n",
    "sigma_2 = 1.1\n",
    "\n",
    "mu_3 = 2.\n",
    "sigma_3 = 2.5\n",
    "\n",
    "\n",
    "partition = 0\n",
    "covariate = jnp.array([2, 0.33, 2])\n",
    "\n",
    "\n",
    "\n",
    "gs_prior_1 = gaussian_prior(mu = mu_1, sigma = sigma_1)\n",
    "gs_prior_2 = gaussian_prior(mu = mu_2, sigma = sigma_2)\n",
    "gs_prior_3 = gaussian_prior(mu = mu_3, sigma = sigma_3)\n",
    "\n",
    "x_samples = gs_prior_1.sample_x(1000000)\n",
    "\n",
    "theta_1 = gs_prior_1.inverse_pivot(x_samples)\n",
    "theta_2 = gs_prior_2.inverse_pivot(x_samples)\n",
    "theta_3 = gs_prior_3.inverse_pivot(x_samples)\n",
    "\n",
    "\n",
    "theta = jnp.array([theta_1, theta_2, theta_3]).T\n",
    "\n",
    "bern_input = model_prob_input(theta, covariate)\n",
    "\n",
    "\n",
    "bern_probs = bernoulli_model_probs(bern_input)\n",
    "\n",
    "prob_y_given_theta_dtheta_samples = bern_probs.model_prob_gradient(partition) ### times the gradient for the CDF(x*theta)\n",
    "\n",
    "pivot_gaussian_inverse_grad_samples_1 = gs_prior_1.grad_inverse_pivot(x_samples)\n",
    "pivot_gaussian_inverse_grad_samples_2 = gs_prior_2.grad_inverse_pivot(x_samples)\n",
    "pivot_gaussian_inverse_grad_samples_3 = gs_prior_3.grad_inverse_pivot(x_samples)\n",
    "\n",
    "\n",
    "\n",
    "ppe_dmu_1 = jnp.mean(prob_y_given_theta_dtheta_samples * covariate[0] * scs.norm.pdf(theta @ covariate) * pivot_gaussian_inverse_grad_samples_1[0,:])\n",
    "ppe_dsigma_1 = jnp.mean(prob_y_given_theta_dtheta_samples * covariate[0] * scs.norm.pdf(theta @ covariate) * pivot_gaussian_inverse_grad_samples_1[1,:])\n",
    "ppe_dmu_2 = jnp.mean(prob_y_given_theta_dtheta_samples * covariate[1] * scs.norm.pdf(theta @ covariate) * pivot_gaussian_inverse_grad_samples_2[0,:])\n",
    "ppe_dsigma_2 = jnp.mean(prob_y_given_theta_dtheta_samples * covariate[1] * scs.norm.pdf(theta @ covariate) * pivot_gaussian_inverse_grad_samples_2[1,:])\n",
    "ppe_dmu_3 = jnp.mean(prob_y_given_theta_dtheta_samples * covariate[2] * scs.norm.pdf(theta @ covariate) * pivot_gaussian_inverse_grad_samples_3[0,:])\n",
    "ppe_dsigma_3 = jnp.mean(prob_y_given_theta_dtheta_samples * covariate[2] * scs.norm.pdf(theta @ covariate) * pivot_gaussian_inverse_grad_samples_3[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array(-0.0776813, dtype=float32),\n",
       " Array(-0.01281741, dtype=float32),\n",
       " Array(-0.0776813, dtype=float32),\n",
       " Array(0.06931718, dtype=float32),\n",
       " Array(0.01143734, dtype=float32),\n",
       " Array(0.06931718, dtype=float32)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ppe_dmu_1, ppe_dmu_2, ppe_dmu_3, ppe_dsigma_1, ppe_dsigma_2, ppe_dsigma_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.02155125, 0.00355596, 0.02155125], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(model_prob_input)(theta[0,:], covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.05460281, -0.00900946, -0.05460281,  0.02418329,  0.00065839,\n",
       "        0.02418329], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bernoulli_probs(partition, lam, covariate_set):\n",
    "\n",
    "    nom = jnp.inner(jnp.array(lam[:3]), covariate_set)\n",
    "    den = jnp.sqrt(1 + covariate_set.T@jnp.diag(jnp.array(lam[3:]))@covariate_set)\n",
    "\n",
    "    p1 = 1 - scs.norm.cdf(nom / den)\n",
    "\n",
    "    if partition == 0:\n",
    "        return p1\n",
    "\n",
    "    return 1 - p1\n",
    "\n",
    "\n",
    "grad(get_bernoulli_probs, argnums=1)(partition, jnp.array([mu_1, mu_2, mu_3, sigma_1, sigma_2, sigma_3]), covariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.12565129 -0.061357606 -0.12207546\n"
     ]
    }
   ],
   "source": [
    "### DOES NOT WORK YET\n",
    "\n",
    "\n",
    "mu_1 = 2.\n",
    "sigma = 1.\n",
    "sigma_1 = 2.\n",
    "\n",
    "partition = np.array([-2.,3.])\n",
    "\n",
    "\n",
    "gs_prior = gaussian_prior(mu = mu_1, sigma = sigma_1)\n",
    "\n",
    "x_samples = gs_prior.sample_x(1000000)\n",
    "\n",
    "theta = gs_prior.inverse_pivot(x_samples)\n",
    "\n",
    "gs_probs = gaussian_model_probs(mu = theta, sigma = sigma)\n",
    "\n",
    "prob_y_given_theta_dtheta_samples = gs_probs.model_prob_gradient(partition)[0,:]\n",
    "\n",
    "prob_y_given_theta_dsigma_samples = gs_probs.model_prob_gradient(partition)[1,:]\n",
    "\n",
    "pivot_gaussian_inverse_grad_samples = gs_prior.grad_inverse_pivot(x_samples)\n",
    "\n",
    "\n",
    "ppe_dmu1 = jnp.mean(prob_y_given_theta_dtheta_samples * pivot_gaussian_inverse_grad_samples[0,:])\n",
    "ppe_dsigma1 = jnp.mean(prob_y_given_theta_dtheta_samples * pivot_gaussian_inverse_grad_samples[1,:])\n",
    "ppe_dsigma = jnp.mean(prob_y_given_theta_dsigma_samples)\n",
    "\n",
    "print(ppe_dmu1, ppe_dsigma, ppe_dsigma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12541339 -0.06110352 -0.12220705]\n"
     ]
    }
   ],
   "source": [
    "def get_gaussian_probs(partition, lam):\n",
    "    \n",
    "    mu_1 = lam[0]\n",
    "    sigma = lam[1]\n",
    "    sigma_1 = lam[2]\n",
    "    \n",
    "    a = partition[0]\n",
    "    b = partition[1]\n",
    "    \n",
    "    p1 = scs.norm.cdf((b - mu_1)/jnp.sqrt(sigma**2 + sigma_1**2)) - scs.norm.cdf((a - mu_1)/jnp.sqrt(sigma**2 + sigma_1**2))    \n",
    "    \n",
    "    return p1\n",
    "\n",
    "lam = jnp.array([2., 1., 2.])\n",
    "partition = jnp.array([-2., 3.])\n",
    "\n",
    "print(grad(get_gaussian_probs, argnums=1)(partition, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppe3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
